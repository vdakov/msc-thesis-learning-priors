{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob - Current Token - Do not delete\n",
    "\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "    print(\"Detected Kaggle environment. Starting setup...\")\n",
    "    token = getpass('Paste your GitLab token: ')\n",
    "    username = \"vdakov\" \n",
    "    repo_url = f\"https://{username}:{token}@gitlab.ewi.tudelft.nl/dsait5000/tom-viering/msc-thesis-vasko.git\"\n",
    "    !git clone {repo_url}\n",
    "    if os.path.exists(\"msc-thesis-vasko\"):\n",
    "        os.chdir(\"msc-thesis-vasko\")\n",
    "        \n",
    "    %pip install -r requirements.txt\n",
    "    if os.path.exists(\"notebooks\"):\n",
    "        os.chdir(\"notebooks\")\n",
    "\n",
    "else:\n",
    "    print(\"Not running in Kaggle. Skipping Git clone and pip install.\")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if os.path.basename(current_dir) == 'notebooks':\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "else:\n",
    "    parent_dir = current_dir\n",
    "\n",
    "src_path = os.path.join(parent_dir, 'src')\n",
    "sys.path.append(src_path)\n",
    "print(f\"Added to sys.path: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.encoders as encoders\n",
    "from training_util import get_uniform_single_eval_pos_sampler, get_weighted_single_eval_pos_sampler, get_cosine_schedule_with_warmup\n",
    "import train\n",
    "from criterion.bar_distribution import BarDistribution, get_bucket_limits\n",
    "from models import positional_encodings\n",
    "from prior_generation import gp_prior, gp_lengthscale_prior\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from samplers.distribution_samplers import DistributionSampler\n",
    "from samplers.distributions import ScaledBernoulli\n",
    "import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'definitions': {\n",
    "        'num_features': 1,\n",
    "        'num_outputs': 100,\n",
    "        'sequence_length': 10,\n",
    "        'max_eval_pos': 9\n",
    "    },\n",
    "    'training_configuration': {\n",
    "        'epochs': 1,\n",
    "        'batch_size': 16,\n",
    "        'warmup_epochs': 25,\n",
    "        'steps_per_epoch': 10,\n",
    "        'validation_context_pos': 9,\n",
    "        'sequence_length': 10,\n",
    "        'lr': 0.0001,\n",
    "        'scheduler': 'cosine_scheduler',\n",
    "        'aggregate_k_gradients': 1,\n",
    "        'context_delimiter_sampling': 'uniform',\n",
    "        'context_delimiter_max_eval_pos': 9,\n",
    "        \"num_test_parameters\": 1\n",
    "    },\n",
    "    'transformer_configuration': {\n",
    "        'emsize': 512,\n",
    "        'fuse_x_y': False,\n",
    "        'nlayers': 6,\n",
    "        'num_features': 1,\n",
    "        'nhead': 4,\n",
    "        'nhid': 1024,\n",
    "        'num_outputs': 100,\n",
    "        'dropout': 0.2,\n",
    "        'input_normalization': True,\n",
    "        'encoder_type': 'linear',\n",
    "        'pos_encoder_type': 'none',\n",
    "        'y_encoder_type': 'linear'\n",
    "    },\n",
    "    'prior_configuration': {\n",
    "        'prior_learning': False,\n",
    "        'type': 'gaussian_process_prior',\n",
    "        'hyperparams': {\n",
    "            'kernel': 'rbf',\n",
    "            'length_scale': 0.5,\n",
    "            'output_scale': 1,\n",
    "            'noise_std': 0.001,\n",
    "            'num_features': 1,\n",
    "            'num_outputs': 100\n",
    "        }\n",
    "    },\n",
    "    'criterion_configuration': {\n",
    "        'loss': 'bar_distribution',\n",
    "        'min_y': -5,\n",
    "        'max_y': 5,\n",
    "        'num_buckets': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# transformer_configuration, training_configuration, criterion, generators, prior, prior_hyperparameters, context_delimiter_generator = load_config.load_config_from_yaml('../src/configs/vanilla_pfn.yaml')\n",
    "transformer_configuration, training_configuration, criterion, generators, prior, prior_hyperparameters, context_delimiter_generator = load_config.parse_config_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb480b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.visualize_datasets(number_of_datasets=5, num_points_per_dataset=200, num_features_per_dataset=1, device='cpu', **prior_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, losses, positional_losses, val_losses = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    save_folder=\"../results\",\n",
    "    load_path=\"../results/test-model/checkpoint.pt\",\n",
    "    experiment_name=\"test-model\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization.training_plots as training_plots \n",
    "training_plots.plot_training_validation_loss(losses, val_losses, title=\"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_dataset = 15\n",
    "num_training_points = num_points_in_dataset - 5\n",
    "num_datasets = 9\n",
    "\n",
    "train_X, train_Y, y_target, _ = prior.get_datasets_from_prior(num_datasets, num_points_in_dataset, 1, **prior_hyperparameters)\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75332f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.prediction_visualization import show_vanilla_pfn_predictions\n",
    "\n",
    "show_vanilla_pfn_predictions(model, train_X, train_Y, num_datasets, num_training_points, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91098735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# transformer_configuration, training_configuration, criterion, generators, prior, prior_hyperparameters, context_delimiter_generator = load_config.load_config_from_yaml('../src/configs/prior_learning_pfn.yaml')\n",
    "config = {\n",
    "    'definitions': {\n",
    "        'num_features': 1,\n",
    "        'num_outputs': 500,\n",
    "        'sequence_length': 25,\n",
    "        'max_eval_pos': 25,\n",
    "    },\n",
    "    'training_configuration': {\n",
    "        'epochs': 250,\n",
    "        'batch_size': 256,\n",
    "        'warmup_epochs': 25,\n",
    "        'steps_per_epoch': 10,\n",
    "        'validation_context_pos': 25,\n",
    "        'sequence_length': 25,\n",
    "        'lr': 0.0001,\n",
    "        'scheduler': 'cosine_scheduler',\n",
    "        'aggregate_k_gradients': 1,\n",
    "        'context_delimiter_sampling': 'constant_last',\n",
    "        'context_delimiter_max_eval_pos': 25,\n",
    "        \"num_test_parameters\": 1\n",
    "    },\n",
    "    'transformer_configuration': {\n",
    "        'emsize': 512,\n",
    "        'fuse_x_y': False,\n",
    "        'nlayers': 6,\n",
    "        'num_features': 1,\n",
    "        'nhead': 4,\n",
    "        'nhid': 1024,\n",
    "        'num_outputs': 100,\n",
    "        'dropout': 0.2,\n",
    "        'input_normalization': True,\n",
    "        'encoder_type': 'linear',\n",
    "        'pos_encoder_type': 'none',\n",
    "        'y_encoder_type': 'linear'\n",
    "    },\n",
    "    'prior_configuration': {\n",
    "        'prior_learning': True,\n",
    "        'type': 'gaussian_process_lengtscale_prior',\n",
    "        'hyperparams': {\n",
    "            'kernel': 'rbf',\n",
    "            \"samplers\": {\n",
    "              \"length_scale\": {\n",
    "                \"distribution\": \"scaled_bernoulli\", #, 'bernoulli'\n",
    "                \"low\": 0.4,\n",
    "                \"high\": 0.6,\n",
    "                \"p\": 0.5,\n",
    "              }\n",
    "    \n",
    "            },\n",
    "            'output_scale': 1,\n",
    "            'noise_std': 0.001,\n",
    "            'num_features': 1,\n",
    "            'num_outputs': 500\n",
    "        }\n",
    "        \"use_cache\": True,\n",
    "        \"cache_path\": \"../cached_datasets/2mil-gp-hyperpriors.pt\"\n",
    "    },\n",
    "    'criterion_configuration': {\n",
    "        'loss': 'bar_distribution',\n",
    "        'min_y': -5,\n",
    "        'max_y': 5,\n",
    "        'num_buckets': 500\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# transformer_configuration, training_configuration, criterion, generators, prior, prior_hyperparameters, context_delimiter_generator = load_config.load_config_from_yaml('../src/configs/prior_learning_pfn.yaml')\n",
    "transformer_configuration, training_configuration, criterion, generators, prior, prior_hyperparameters, context_delimiter_generator = load_config.parse_config_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior.cache_datasets(1280000, 256, 25, 1, \"cpu\", **prior_hyperparameters)\n",
    "# prior.save_cache(\"../cached_datasets/1p28лю-gp-hyperprior.pt\")\n",
    "# prior.sample_cache(4, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, losses, positional_losses, val_losses = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    # load_path=\"../results/test-model-2/checkpoint.pt\",\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    save_folder=\"../results\",\n",
    "    experiment_name=\"test-model-2\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0424c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_dataset = 100\n",
    "hyperparameters = { 'kernel': \"rbf\", 'length_scale': 0.4, \"samplers\": {\"length_scale\": DistributionSampler(ScaledBernoulli(low=0.4, high=0.6, prob=1.0))}}\n",
    "prior.visualize_datasets(number_of_datasets=5, num_points_per_dataset=num_points_in_dataset, num_features_per_dataset=1, device='cpu', **hyperparameters)\n",
    "train_X, train_Y, y_target, lengthscale = prior.get_datasets_from_prior(1, num_points_in_dataset, 1, **hyperparameters)\n",
    "\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)\n",
    "num_training_points = num_points_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41288866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_evaluation.evaluate_with_context import evaluate_parameter_distributions_on_model\n",
    "\n",
    "outputs = evaluate_parameter_distributions_on_model(train_X, train_Y, model, device, num_training_points)\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a893f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def show_parameter_distributions_predictions(outputs, threshold, parameters):\n",
    "    num_distributions = len(parameters)\n",
    "    borders_all = model.criterion.borders.detach().cpu().numpy()\n",
    "    widths = np.diff(borders_all)\n",
    "    print(outputs.shape)\n",
    "    for i in range(num_distributions):\n",
    "\n",
    "        left_edges = borders_all[:-1]\n",
    "        values = torch.squeeze(outputs[i]).detach().cpu().numpy()\n",
    "        mask = values > threshold\n",
    "\n",
    "        plt.bar(left_edges[mask], values[mask], width=widths[mask], align='edge', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "        plt.xlabel(parameters[i])\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.title(f\"Focus on Significant Factors (> {threshold})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_parameter_distributions_predictions(outputs, 0.01, ['Lengthscale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rbf_kernel(X1, X2, lengthscale, variance=1.0):\n",
    "    dists = cdist(X1, X2, metric='sqeuclidean')\n",
    "    return variance * np.exp(-0.5 * dists / (lengthscale ** 2))\n",
    "\n",
    "\n",
    "true_lengthscale = 0.4\n",
    "X = np.random.uniform(0, 1, size=(10, 1))\n",
    "K_true = rbf_kernel(X, X, lengthscale=true_lengthscale)\n",
    "y = np.random.multivariate_normal(mean=np.zeros(len(X)), cov=K_true).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def nll_fn_robust(theta, X, y):\n",
    "    ls = np.exp(theta[0])      # Lengthscale\n",
    "    sigma_f = np.exp(theta[1]) # Signal Variance (Output scale)\n",
    "    sigma_n = np.exp(theta[2]) # Noise Variance\n",
    "    \n",
    "    n = len(y)\n",
    "    # Ensure X is 2D and y is 1D\n",
    "    X = X.reshape(-1, 1) if X.ndim == 1 else X\n",
    "    y = y.ravel()\n",
    "\n",
    "    K = sigma_f**2 * np.exp(-0.5 * cdist(X, X, 'sqeuclidean') / ls**2) + (sigma_n**2 + 1e-6) * np.eye(n)\n",
    "    \n",
    "    try:\n",
    "        L = np.linalg.cholesky(K)\n",
    "        alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))\n",
    "        data_fit = 0.5 * y.T @ alpha\n",
    "        complexity = np.sum(np.log(np.diag(L)))\n",
    "        constant = 0.5 * n * np.log(2 * np.pi)\n",
    "        return (data_fit + complexity + constant).item()\n",
    "    except np.linalg.LinAlgError:\n",
    "        return 1e10\n",
    "\n",
    "# Optimize Lengthscale, Signal Variance, and Noise Variance\n",
    "initial_params = [np.log(0.4), np.log(1.0), np.log(1e-3)]\n",
    "res = minimize(nll_fn_robust, x0=initial_params, args=(X, y), method='L-BFGS-B')\n",
    "\n",
    "recovered_ls = np.exp(res.x[0])\n",
    "\n",
    "print(f\"True Lengthscale: {true_lengthscale}\")\n",
    "print(f\"Recovered Lengthscale: {recovered_ls:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
