{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Securely input your token\n",
    "token = getpass('Paste your GitLab token: ')\n",
    "\n",
    "# Set the repository URL\n",
    "# repo_url = \"https://oauth2:\" + token + \"@gitlab.ewi.tudelft.nl/dsait5000/tom-viering/msc-thesis-vasko.git\"\n",
    "username = \"vdakov\" \n",
    "\n",
    "# Syntax: https://<username>:<token>@<domain>/...\n",
    "repo_url = f\"https://{username}:{token}@gitlab.ewi.tudelft.nl/dsait5000/tom-viering/msc-thesis-vasko.git\"\n",
    "\n",
    "!git clone {repo_url}\n",
    "\n",
    "# Clone the repository\n",
    "# !git clone {repo_url}\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob\n",
    "# Verify clone\n",
    "os.chdir(\"msc-thesis-vasko\")\n",
    "%pip install -r requirements.txt\n",
    "os.chdir(\"notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c539e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /home/vdakov/Desktop/thesis/msc-thesis-vasko\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(os.path.join(parent_dir, 'src'))\n",
    "print(f\"Added to sys.path: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f689e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "class DistributionSampler:\n",
    "    def __init__(self, distribution: Distribution):\n",
    "        \"\"\"\n",
    "        :param distribution: An instantiated torch.distributions object \n",
    "                             (e.g., Uniform(0.1, 3.0), Gamma(2.0, 2.0))\n",
    "        \"\"\"\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def sample(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the distribution with the given batch size.\n",
    "        Returns a tensor of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # PyTorch distributions expect a tuple/torch.Size for sampling\n",
    "        return self.distribution.sample(torch.Size([batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622c4e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (3549239173.py, line 75)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtransformer_configuration = (emsize, nhead, nhid, nlayers, dropout, num_features, num_outputs, input_normalization, y_encoder_generator, sequence_length, fuse_x_y, prior_prediction, num_test_parameters = 1)\u001b[39m\n                                                                                                                                                                                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import models.encoders as encoders\n",
    "from training_util import get_uniform_single_eval_pos_sampler, get_weighted_single_eval_pos_sampler, get_cosine_schedule_with_warmup\n",
    "import train\n",
    "from criterion.bar_distribution import BarDistribution, get_bucket_limits\n",
    "from models import positional_encodings\n",
    "from prior_generation import gp_prior, gp_lengthscale_prior\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "epochs = 3\n",
    "batch_size =  256\n",
    "warmup_epochs = 25\n",
    "steps_per_epoch = 10\n",
    "lr = 0.0001\n",
    "sequence_length = 10\n",
    "emsize = 512\n",
    "fuse_x_y = False\n",
    "nlayers = 6\n",
    "nhead = 4\n",
    "nhid = 1024\n",
    "dropout = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_buckets = 1000\n",
    "min_y = -5\n",
    "max_y = 5\n",
    "num_features = 1\n",
    "num_outputs = 1000\n",
    "my_prior_dist = dist.Uniform(low=0.1, high=1)\n",
    "\n",
    "sampler = DistributionSampler(my_prior_dist)\n",
    "# prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", 'length_scale': 0.5}\n",
    "prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", 'length_scale': 0.5, \"length_scale_sampling\": sampler}\n",
    "input_normalization = True\n",
    "aggregate_k_gradients=1\n",
    "encoder_type = 'linear'  # 'linear' or 'mlp'\n",
    "y_encoder_type = 'linear'\n",
    "pos_encoder_type = 'none'  # 'sinus', 'learned', 'none'\n",
    "scheduler = get_cosine_schedule_with_warmup\n",
    "prior_prediction = False\n",
    "num_test_parameters = 1\n",
    "\n",
    "def get_encoder_generator(encoder):\n",
    "        if encoder == 'linear':\n",
    "            encoder_generator = encoders.LinearEncoder\n",
    "        elif encoder == 'mlp':\n",
    "            encoder_generator = encoders.MLPEncoder\n",
    "        else:\n",
    "            raise NotImplementedError(f'A {encoder} encoder is not valid.')\n",
    "        return encoder_generator\n",
    "\n",
    "encoder_generator = get_encoder_generator(encoder_type)\n",
    "y_encoder_generator = get_encoder_generator(y_encoder_type)\n",
    "\n",
    "if pos_encoder_type== 'sinus':\n",
    "    pos_encoder_generator = positional_encodings.PositionalEncoding\n",
    "elif pos_encoder_type == 'learned':\n",
    "    pos_encoder_generator = positional_encodings.LearnedPositionalEncoding\n",
    "else:\n",
    "    pos_encoder_generator = positional_encodings.NoPositionalEncoding\n",
    "    \n",
    "permutation_invariant_max_eval_pos = sequence_length - 1\n",
    "permutation_invariant_sampling = 'uniform'\n",
    "\n",
    "if permutation_invariant_max_eval_pos is not None:\n",
    "    if permutation_invariant_sampling == 'weighted':\n",
    "        get_sampler = get_weighted_single_eval_pos_sampler\n",
    "    elif permutation_invariant_sampling == 'uniform':\n",
    "        get_sampler = get_uniform_single_eval_pos_sampler\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "context_delimiter_generator = get_sampler(permutation_invariant_max_eval_pos)\n",
    "\n",
    "transformer_configuration = (emsize, nhead, nhid, nlayers, dropout, num_features, num_outputs, input_normalization, y_encoder_generator, sequence_length, fuse_x_y, prior_prediction, num_test_parameters) \n",
    "training_configuration = (epochs, steps_per_epoch, batch_size, sequence_length, lr, warmup_epochs, aggregate_k_gradients, scheduler, prior_prediction)\n",
    "generators = (encoder_generator, y_encoder_generator, pos_encoder_generator)\n",
    "prior = gp_prior.GaussianProcessPriorGenerator()\n",
    "# prior = gp_lengthscale_prior.GaussianProcessHyperPriorGenerator()\n",
    "print(prior.name)\n",
    "criterion = BarDistribution(borders=get_bucket_limits(num_buckets, full_range=(min_y, max_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb480b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'kernel': \"rbf\", 'length_scale': 0.5}\n",
    "prior.visualize_datasets(number_of_datasets=5, num_points_per_dataset=200, num_features_per_dataset=1, device='cpu', **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d125b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cpu...\n",
      "Using cpu:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdakov/.conda/envs/thesis/lib/python3.14/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/vdakov/.conda/envs/thesis/lib/python3.14/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6. Run Training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m losses, positional_losses, val_losses,  model = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprior_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Passing the wrapper\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformer_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformer_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_delimiter_generator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_delimiter_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/msc-thesis-vasko/src/train.py:57\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(prior_dataloader, criterion, transformer_configuration, generators, training_configuration, prior_hyperparameters, load_path, context_delimiter_generator, device, verbose, save_path, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m     model.load_state_dict(load_path)\n\u001b[32m     54\u001b[39m model.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m scheduler = scheduler(optimizer, warmup_epochs, epochs)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_one_epoch\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/adamw.py:37\u001b[39m, in \u001b[36mAdamW.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     params: ParamsT,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fused: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = {\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m: betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m: decoupled_weight_decay,\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/optimizer.py:401\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    398\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/symbolic_convert.py:103\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuncname_cache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_funcname\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_graph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphCompileReason, OutputGraph\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolyfills\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m impl_CONTAINS_OP_fallback\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreplay_record\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DummyModule, ExecutionRecorder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/output_graph.py:101\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_interface_for_device\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     BackendCompilerFailed,\n\u001b[32m     96\u001b[39m     exceptions_allowed_to_be_fallback,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     unimplemented_v2_with_warning,\n\u001b[32m    100\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_deduplication\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_graph_deduplication\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_region_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphRegionTracker\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/graph_deduplication.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreductions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StorageWeakRef\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ordered_set\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedSet\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_region_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node, Region\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _detect_cycles, _get_flat_args, _get_flat_args_unique\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Represents an index into the region\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# to select a node and then\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# an index into that node's\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# flattened arguments\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1369\u001b[39m     module = sys.modules.get(name, _NEEDS_LOADING)\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n\u001b[32m   1377\u001b[39m _lock_unlock_module(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1342\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1340\u001b[39m     parent_spec._uninitialized_submodules.append(child)\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     module = \u001b[43m_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parent_spec:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:938\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n\u001b[32m    935\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmissing loader\u001b[39m\u001b[33m'\u001b[39m, name=spec.name)\n\u001b[32m    936\u001b[39m         \u001b[38;5;66;03m# A namespace package so do nothing.\u001b[39;00m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:755\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexec_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module):\n\u001b[32m    754\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the module.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     code = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    757\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    758\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:888\u001b[39m, in \u001b[36mSourceLoader.get_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n\u001b[32m    885\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m                 _bootstrap._verbose_message(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m matches \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m, bytecode_path,\n\u001b[32m    887\u001b[39m                                             source_path)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mbytecode_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbytecode_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    892\u001b[39m     source_bytes = \u001b[38;5;28mself\u001b[39m.get_data(source_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:511\u001b[39m, in \u001b[36m_compile_bytecode\u001b[39m\u001b[34m(data, name, bytecode_path, source_path)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_bytecode\u001b[39m(data, name=\u001b[38;5;28;01mNone\u001b[39;00m, bytecode_path=\u001b[38;5;28;01mNone\u001b[39;00m, source_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    510\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compile bytecode as found in a pyc.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     code = \u001b[43mmarshal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(code, _code_type):\n\u001b[32m    513\u001b[39m         _bootstrap._verbose_message(\u001b[33m'\u001b[39m\u001b[33mcode object from \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m'\u001b[39m, bytecode_path)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 6. Run Training\n",
    "print(f\"Starting training on {device}...\")\n",
    "losses, positional_losses, val_losses,  model = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    load_path=None,\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    save_path=None,\n",
    ")\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(x=np.arange(0, len(losses)), y=np.array(losses), label=\"Training\")\n",
    "sns.lineplot(x=np.arange(0, len(losses)), y=np.array(val_losses), label=\"Validation\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_dataset = 15\n",
    "train_X, train_Y, y_target = prior.get_datasets_from_prior(9, num_points_in_dataset, 1, **hyperparameters)\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)\n",
    "num_training_points = num_points_in_dataset - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75332f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mmodel\u001b[49m.to(device)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Set up grid for subplots\u001b[39;00m\n\u001b[32m      3\u001b[39m fig, axes = plt.subplots(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m8\u001b[39m)) \n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model.to(device)\n",
    "# Set up grid for subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 8)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for batch_index in range(9):\n",
    "    ax = axes[batch_index] \n",
    "    train_x = train_X[:num_training_points, batch_index, :]\n",
    "    train_y = train_Y[:num_training_points, batch_index]\n",
    "    test_x = train_X[:, batch_index, :]\n",
    "    with torch.no_grad():\n",
    "        logits = model((torch.cat((train_x, test_x)), torch.cat((train_y, torch.zeros(len(test_x), device=device)))), context_pos=num_training_points - 1)\n",
    "\n",
    "        pred_means = model.criterion.mean(logits)\n",
    "        pred_confs = model.criterion.quantile(logits)\n",
    "        pred_means = pred_means[-len(test_x):]\n",
    "        pred_confs = pred_confs[-len(test_x):]\n",
    "        # Plot scatter points for training data\n",
    "        ax.scatter(train_x[..., 0].cpu().numpy(), train_y.cpu().numpy(), label=\"Training Data\")\n",
    "\n",
    "    # Plot model predictions\n",
    "    order_test_x = test_x[:, 0].cpu().argsort()\n",
    "    ax.plot(\n",
    "        test_x[order_test_x, 0].cpu().numpy(),\n",
    "        pred_means[order_test_x].cpu().numpy(),\n",
    "        color='green',\n",
    "        label='pfn'\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        test_x[order_test_x, 0].cpu().numpy(),\n",
    "        pred_confs[order_test_x][:, 0].cpu().numpy(),\n",
    "        pred_confs[order_test_x][:, 1].cpu().numpy(),\n",
    "        alpha=.1,\n",
    "        color='green'\n",
    "    )\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6073d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import models.encoders as encoders\n",
    "from training_util import get_uniform_single_eval_pos_sampler, get_weighted_single_eval_pos_sampler, get_cosine_schedule_with_warmup\n",
    "import train\n",
    "from criterion.bar_distribution import BarDistribution, get_bucket_limits\n",
    "from models import positional_encodings\n",
    "from prior_generation import gp_prior, gp_lengthscale_prior\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "epochs = 10\n",
    "batch_size =  256\n",
    "warmup_epochs = 25\n",
    "steps_per_epoch = 10\n",
    "lr = 0.0001\n",
    "sequence_length = 10\n",
    "emsize = 512\n",
    "fuse_x_y = False\n",
    "nlayers = 6\n",
    "nhead = 4\n",
    "nhid = 1024\n",
    "dropout = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_buckets = 250\n",
    "min_y = -5\n",
    "max_y = 5\n",
    "num_features = 1\n",
    "num_outputs = 250\n",
    "my_prior_dist = dist.Uniform(low=0.4, high=0.6)\n",
    "sampler = DistributionSampler(my_prior_dist)\n",
    "prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", \"length_scale_sampling\": sampler}\n",
    "input_normalization = True\n",
    "aggregate_k_gradients=1\n",
    "encoder_type = 'linear'  # 'linear' or 'mlp'\n",
    "y_encoder_type = 'linear'\n",
    "pos_encoder_type = 'none'  # 'sinus', 'learned', 'none'\n",
    "scheduler = get_cosine_schedule_with_warmup\n",
    "prior_prediction = True\n",
    "num_test_parameters = 1\n",
    "\n",
    "def get_encoder_generator(encoder):\n",
    "        if encoder == 'linear':\n",
    "            encoder_generator = encoders.LinearEncoder\n",
    "        elif encoder == 'mlp':\n",
    "            encoder_generator = encoders.MLPEncoder\n",
    "        else:\n",
    "            raise NotImplementedError(f'A {encoder} encoder is not valid.')\n",
    "        return encoder_generator\n",
    "\n",
    "encoder_generator = get_encoder_generator(encoder_type)\n",
    "y_encoder_generator = get_encoder_generator(y_encoder_type)\n",
    "\n",
    "if pos_encoder_type== 'sinus':\n",
    "    pos_encoder_generator = positional_encodings.PositionalEncoding\n",
    "elif pos_encoder_type == 'learned':\n",
    "    pos_encoder_generator = positional_encodings.LearnedPositionalEncoding\n",
    "else:\n",
    "    pos_encoder_generator = positional_encodings.NoPositionalEncoding\n",
    "    \n",
    "permutation_invariant_max_eval_pos = sequence_length - 1\n",
    "permutation_invariant_sampling = 'uniform'\n",
    "\n",
    "if permutation_invariant_max_eval_pos is not None:\n",
    "    if permutation_invariant_sampling == 'weighted':\n",
    "        get_sampler = get_weighted_single_eval_pos_sampler\n",
    "    elif permutation_invariant_sampling == 'uniform':\n",
    "        get_sampler = get_uniform_single_eval_pos_sampler\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "context_delimiter_generator = get_sampler(permutation_invariant_max_eval_pos)\n",
    "\n",
    "transformer_configuration = (emsize, nhead, nhid, nlayers, dropout, num_features, num_outputs, input_normalization, y_encoder_generator, sequence_length, fuse_x_y, prior_prediction, num_test_parameters) \n",
    "training_configuration = (epochs, steps_per_epoch, batch_size, sequence_length, lr, warmup_epochs, aggregate_k_gradients, scheduler, prior_prediction)\n",
    "generators = (encoder_generator, y_encoder_generator, pos_encoder_generator)\n",
    "# prior = gp_prior.GaussianProcessPriorGenerator()\n",
    "prior = gp_lengthscale_prior.GaussianProcessHyperPriorGenerator()\n",
    "criterion = BarDistribution(borders=get_bucket_limits(num_buckets, full_range=(min_y, max_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52042e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cpu...\n",
      "Using cpu:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss -0.96 | pos loss   nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,-0.96, lr 3.6e-05val score 2.288403272628784: 100%|██████████| 10/10 [04:08<00:00, 24.81s/it]               \n"
     ]
    }
   ],
   "source": [
    "# 6. Run Training\n",
    "print(f\"Starting training on {device}...\")\n",
    "losses, positional_losses, val_losses,  model = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    load_path=None,\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    save_path=None,\n",
    ")\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0424c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_dataset = 15\n",
    "hyperparameters = { 'kernel': \"rbf\", 'length_scale': 0.4, \"length_scale_sampling\": DistributionSampler(dist.Uniform(low=0.4, high=0.41))}\n",
    "train_X, train_Y, y_target, lengthscale = prior.get_datasets_from_prior(1, num_points_in_dataset, 1, **hyperparameters)\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)\n",
    "num_training_points = num_points_in_dataset - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46da943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 1]) torch.Size([10, 1])\n",
      "torch.Size([2, 1, 250])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0011, 0.0007, 0.0008, 0.0009, 0.0007, 0.0009, 0.0016, 0.0010, 0.0017,\n",
       "         0.0018, 0.0008, 0.0011, 0.0012, 0.0017, 0.0010, 0.0009, 0.0026, 0.0013,\n",
       "         0.0009, 0.0022, 0.0010, 0.0005, 0.0019, 0.0009, 0.0014, 0.0018, 0.0022,\n",
       "         0.0017, 0.0013, 0.0006, 0.0011, 0.0010, 0.0021, 0.0015, 0.0011, 0.0022,\n",
       "         0.0009, 0.0011, 0.0010, 0.0010, 0.0008, 0.0010, 0.0013, 0.0012, 0.0007,\n",
       "         0.0013, 0.0011, 0.0017, 0.0013, 0.0009, 0.0013, 0.0010, 0.0014, 0.0011,\n",
       "         0.0008, 0.0009, 0.0011, 0.0020, 0.0016, 0.0013, 0.0012, 0.0011, 0.0010,\n",
       "         0.0006, 0.0005, 0.0005, 0.0009, 0.0022, 0.0011, 0.0008, 0.0012, 0.0009,\n",
       "         0.0013, 0.0010, 0.0007, 0.0011, 0.0011, 0.0008, 0.0010, 0.0007, 0.0012,\n",
       "         0.0006, 0.0009, 0.0011, 0.0008, 0.0009, 0.0010, 0.0016, 0.0010, 0.0009,\n",
       "         0.0010, 0.0011, 0.0018, 0.0011, 0.0017, 0.0031, 0.0010, 0.0012, 0.0008,\n",
       "         0.0007, 0.0011, 0.0018, 0.0004, 0.0016, 0.0022, 0.0009, 0.0013, 0.0008,\n",
       "         0.0009, 0.0016, 0.0011, 0.0008, 0.0012, 0.0010, 0.0011, 0.0013, 0.0011,\n",
       "         0.0019, 0.0012, 0.0010, 0.0004, 0.0013, 0.0015, 0.0008, 0.0009, 0.0012,\n",
       "         0.0019, 0.0008, 0.0010, 0.0008, 0.0013, 0.0018, 0.0010, 0.0010, 0.0019,\n",
       "         0.1440, 0.1253, 0.1681, 0.1226, 0.1428, 0.0011, 0.0015, 0.0010, 0.0013,\n",
       "         0.0007, 0.0015, 0.0011, 0.0015, 0.0010, 0.0011, 0.0014, 0.0010, 0.0008,\n",
       "         0.0010, 0.0019, 0.0010, 0.0013, 0.0010, 0.0012, 0.0013, 0.0007, 0.0016,\n",
       "         0.0007, 0.0027, 0.0009, 0.0014, 0.0017, 0.0013, 0.0005, 0.0016, 0.0015,\n",
       "         0.0013, 0.0006, 0.0015, 0.0017, 0.0007, 0.0009, 0.0006, 0.0012, 0.0018,\n",
       "         0.0013, 0.0010, 0.0013, 0.0013, 0.0007, 0.0009, 0.0011, 0.0005, 0.0022,\n",
       "         0.0012, 0.0011, 0.0010, 0.0012, 0.0014, 0.0009, 0.0011, 0.0017, 0.0019,\n",
       "         0.0011, 0.0014, 0.0006, 0.0020, 0.0014, 0.0017, 0.0008, 0.0012, 0.0010,\n",
       "         0.0012, 0.0036, 0.0013, 0.0012, 0.0027, 0.0009, 0.0013, 0.0018, 0.0017,\n",
       "         0.0012, 0.0016, 0.0014, 0.0023, 0.0013, 0.0007, 0.0014, 0.0008, 0.0014,\n",
       "         0.0013, 0.0009, 0.0011, 0.0011, 0.0021, 0.0013, 0.0011, 0.0013, 0.0008,\n",
       "         0.0009, 0.0010, 0.0007, 0.0009, 0.0012, 0.0010, 0.0011, 0.0011, 0.0015,\n",
       "         0.0005, 0.0010, 0.0011, 0.0018, 0.0016, 0.0008, 0.0011]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "model = model.to(device)\n",
    "train_x = train_X[:num_training_points]\n",
    "train_y = train_Y[:num_training_points]\n",
    "\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "with torch.no_grad():\n",
    "    logits = model((train_x, train_y), context_pos=num_training_points - 1)\n",
    "    print(logits.shape)\n",
    "    outputs = torch.exp(torch.log_softmax(logits, -1))\n",
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "torch.Size([250])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "borders = model.criterion.borders.detach().cpu().numpy() \n",
    "borders = borders[1:]\n",
    "print(borders.shape)\n",
    "values = torch.squeeze(outputs[1])\n",
    "print(values.shape)\n",
    "threshold = 0.1\n",
    "mask = torch.squeeze(outputs[1] > threshold)\n",
    "#outputs[1] because this is the lengthscale \n",
    "plt.bar(borders[mask], values[mask], log=True, linewidth=0.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
