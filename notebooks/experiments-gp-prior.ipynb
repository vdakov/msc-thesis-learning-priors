{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Securely input your token\n",
    "token = getpass('Paste your GitLab token: ')\n",
    "\n",
    "# Set the repository URL\n",
    "# repo_url = \"https://oauth2:\" + token + \"@gitlab.ewi.tudelft.nl/dsait5000/tom-viering/msc-thesis-vasko.git\"\n",
    "username = \"vdakov\" \n",
    "\n",
    "# Syntax: https://<username>:<token>@<domain>/...\n",
    "repo_url = f\"https://{username}:{token}@gitlab.ewi.tudelft.nl/dsait5000/tom-viering/msc-thesis-vasko.git\"\n",
    "\n",
    "!git clone {repo_url}\n",
    "\n",
    "# Clone the repository\n",
    "# !git clone {repo_url}\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob\n",
    "# Verify clone\n",
    "os.chdir(\"msc-thesis-vasko\")\n",
    "%pip install -r requirements.txt\n",
    "os.chdir(\"notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c539e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /home/vdakov/Desktop/thesis/msc-thesis-vasko\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(os.path.join(parent_dir, 'src'))\n",
    "print(f\"Added to sys.path: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f689e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "class DistributionSampler:\n",
    "    def __init__(self, distribution: Distribution):\n",
    "        \"\"\"\n",
    "        :param distribution: An instantiated torch.distributions object \n",
    "                             (e.g., Uniform(0.1, 3.0), Gamma(2.0, 2.0))\n",
    "        \"\"\"\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def sample(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the distribution with the given batch size.\n",
    "        Returns a tensor of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # PyTorch distributions expect a tuple/torch.Size for sampling\n",
    "        return self.distribution.sample(torch.Size([batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process Prior\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import models.encoders as encoders\n",
    "from training_util import get_uniform_single_eval_pos_sampler, get_weighted_single_eval_pos_sampler, get_cosine_schedule_with_warmup\n",
    "import train\n",
    "from criterion.bar_distribution import BarDistribution, get_bucket_limits\n",
    "from models import positional_encodings\n",
    "from prior_generation import gp_prior, gp_lengthscale_prior\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "epochs = 3\n",
    "batch_size =  256\n",
    "warmup_epochs = 25\n",
    "steps_per_epoch = 10\n",
    "lr = 0.0001\n",
    "sequence_length = 10\n",
    "emsize = 512\n",
    "fuse_x_y = False\n",
    "nlayers = 6\n",
    "nhead = 4\n",
    "nhid = 1024\n",
    "dropout = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_buckets = 100\n",
    "min_y = -10\n",
    "max_y = 10\n",
    "num_features = 1\n",
    "num_outputs = 100\n",
    "my_prior_dist = dist.Uniform(low=0.1, high=1)\n",
    "\n",
    "sampler = DistributionSampler(my_prior_dist)\n",
    "# prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", 'length_scale': 0.5}\n",
    "prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", 'length_scale': 0.5, \"length_scale_sampling\": sampler}\n",
    "input_normalization = True\n",
    "aggregate_k_gradients=1\n",
    "encoder_type = 'linear'  # 'linear' or 'mlp'\n",
    "y_encoder_type = 'linear'\n",
    "pos_encoder_type = 'none'  # 'sinus', 'learned', 'none'\n",
    "scheduler = get_cosine_schedule_with_warmup\n",
    "prior_prediction = False\n",
    "num_test_parameters = 1\n",
    "\n",
    "def get_encoder_generator(encoder):\n",
    "        if encoder == 'linear':\n",
    "            encoder_generator = encoders.LinearEncoder\n",
    "        elif encoder == 'mlp':\n",
    "            encoder_generator = encoders.MLPEncoder\n",
    "        else:\n",
    "            raise NotImplementedError(f'A {encoder} encoder is not valid.')\n",
    "        return encoder_generator\n",
    "\n",
    "encoder_generator = get_encoder_generator(encoder_type)\n",
    "y_encoder_generator = get_encoder_generator(y_encoder_type)\n",
    "\n",
    "if pos_encoder_type== 'sinus':\n",
    "    pos_encoder_generator = positional_encodings.PositionalEncoding\n",
    "elif pos_encoder_type == 'learned':\n",
    "    pos_encoder_generator = positional_encodings.LearnedPositionalEncoding\n",
    "else:\n",
    "    pos_encoder_generator = positional_encodings.NoPositionalEncoding\n",
    "    \n",
    "permutation_invariant_max_eval_pos = sequence_length - 1\n",
    "permutation_invariant_sampling = 'uniform'\n",
    "\n",
    "if permutation_invariant_max_eval_pos is not None:\n",
    "    if permutation_invariant_sampling == 'weighted':\n",
    "        get_sampler = get_weighted_single_eval_pos_sampler\n",
    "    elif permutation_invariant_sampling == 'uniform':\n",
    "        get_sampler = get_uniform_single_eval_pos_sampler\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "context_delimiter_generator = get_sampler(permutation_invariant_max_eval_pos)\n",
    "\n",
    "transformer_configuration = (emsize, nhead, nhid, nlayers, dropout, num_features, num_outputs, input_normalization, y_encoder_generator, sequence_length, fuse_x_y, prior_prediction, num_test_parameters = 1) \n",
    "training_configuration = (epochs, steps_per_epoch, batch_size, sequence_length, lr, warmup_epochs, aggregate_k_gradients, scheduler, prior_prediction)\n",
    "generators = (encoder_generator, y_encoder_generator, pos_encoder_generator)\n",
    "prior = gp_prior.GaussianProcessPriorGenerator()\n",
    "# prior = gp_lengthscale_prior.GaussianProcessHyperPriorGenerator()\n",
    "print(prior.name)\n",
    "criterion = BarDistribution(borders=get_bucket_limits(num_buckets, full_range=(min_y, max_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb480b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'kernel': \"rbf\", 'length_scale': 0.5}\n",
    "prior.visualize_datasets(number_of_datasets=5, num_points_per_dataset=200, num_features_per_dataset=1, device='cpu', **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d125b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cpu...\n",
      "Using cpu:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdakov/.conda/envs/thesis/lib/python3.14/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/vdakov/.conda/envs/thesis/lib/python3.14/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6. Run Training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m losses, positional_losses, val_losses,  model = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprior_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Passing the wrapper\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformer_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformer_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_delimiter_generator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_delimiter_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/msc-thesis-vasko/src/train.py:57\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(prior_dataloader, criterion, transformer_configuration, generators, training_configuration, prior_hyperparameters, load_path, context_delimiter_generator, device, verbose, save_path, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m     model.load_state_dict(load_path)\n\u001b[32m     54\u001b[39m model.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m scheduler = scheduler(optimizer, warmup_epochs, epochs)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_one_epoch\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/adamw.py:37\u001b[39m, in \u001b[36mAdamW.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     params: ParamsT,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fused: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = {\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m: betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m: decoupled_weight_decay,\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/optim/optimizer.py:401\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    398\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/symbolic_convert.py:103\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuncname_cache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_funcname\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_graph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphCompileReason, OutputGraph\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolyfills\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m impl_CONTAINS_OP_fallback\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreplay_record\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DummyModule, ExecutionRecorder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/output_graph.py:101\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_interface_for_device\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     BackendCompilerFailed,\n\u001b[32m     96\u001b[39m     exceptions_allowed_to_be_fallback,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     unimplemented_v2_with_warning,\n\u001b[32m    100\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_deduplication\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_graph_deduplication\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_region_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphRegionTracker\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/thesis/lib/python3.14/site-packages/torch/_dynamo/graph_deduplication.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreductions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StorageWeakRef\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ordered_set\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedSet\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_region_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node, Region\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _detect_cycles, _get_flat_args, _get_flat_args_unique\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Represents an index into the region\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# to select a node and then\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# an index into that node's\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# flattened arguments\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1369\u001b[39m     module = sys.modules.get(name, _NEEDS_LOADING)\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n\u001b[32m   1377\u001b[39m _lock_unlock_module(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1342\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1340\u001b[39m     parent_spec._uninitialized_submodules.append(child)\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     module = \u001b[43m_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parent_spec:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:938\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n\u001b[32m    935\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmissing loader\u001b[39m\u001b[33m'\u001b[39m, name=spec.name)\n\u001b[32m    936\u001b[39m         \u001b[38;5;66;03m# A namespace package so do nothing.\u001b[39;00m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:755\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexec_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module):\n\u001b[32m    754\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the module.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     code = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    757\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    758\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:888\u001b[39m, in \u001b[36mSourceLoader.get_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n\u001b[32m    885\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m                 _bootstrap._verbose_message(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m matches \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m, bytecode_path,\n\u001b[32m    887\u001b[39m                                             source_path)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mbytecode_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbytecode_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    892\u001b[39m     source_bytes = \u001b[38;5;28mself\u001b[39m.get_data(source_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:511\u001b[39m, in \u001b[36m_compile_bytecode\u001b[39m\u001b[34m(data, name, bytecode_path, source_path)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_bytecode\u001b[39m(data, name=\u001b[38;5;28;01mNone\u001b[39;00m, bytecode_path=\u001b[38;5;28;01mNone\u001b[39;00m, source_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    510\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compile bytecode as found in a pyc.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     code = \u001b[43mmarshal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(code, _code_type):\n\u001b[32m    513\u001b[39m         _bootstrap._verbose_message(\u001b[33m'\u001b[39m\u001b[33mcode object from \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m'\u001b[39m, bytecode_path)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 6. Run Training\n",
    "print(f\"Starting training on {device}...\")\n",
    "losses, positional_losses, val_losses,  model = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    load_path=None,\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    save_path=None,\n",
    ")\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(x=np.arange(0, len(losses)), y=np.array(losses), label=\"Training\")\n",
    "sns.lineplot(x=np.arange(0, len(losses)), y=np.array(val_losses), label=\"Validation\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_dataset = 15\n",
    "train_X, train_Y, y_target = prior.get_datasets_from_prior(9, num_points_in_dataset, 1, **hyperparameters)\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)\n",
    "num_training_points = num_points_in_dataset - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75332f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mmodel\u001b[49m.to(device)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Set up grid for subplots\u001b[39;00m\n\u001b[32m      3\u001b[39m fig, axes = plt.subplots(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m8\u001b[39m)) \n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model.to(device)\n",
    "# Set up grid for subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 8)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for batch_index in range(9):\n",
    "    ax = axes[batch_index] \n",
    "    train_x = train_X[:num_training_points, batch_index, :]\n",
    "    train_y = train_Y[:num_training_points, batch_index]\n",
    "    test_x = train_X[:, batch_index, :]\n",
    "    with torch.no_grad():\n",
    "        logits = model((torch.cat((train_x, test_x)), torch.cat((train_y, torch.zeros(len(test_x), device=device)))), context_pos=num_training_points - 1)\n",
    "\n",
    "        pred_means = model.criterion.mean(logits)\n",
    "        pred_confs = model.criterion.quantile(logits)\n",
    "        pred_means = pred_means[-len(test_x):]\n",
    "        pred_confs = pred_confs[-len(test_x):]\n",
    "        # Plot scatter points for training data\n",
    "        ax.scatter(train_x[..., 0].cpu().numpy(), train_y.cpu().numpy(), label=\"Training Data\")\n",
    "\n",
    "    # Plot model predictions\n",
    "    order_test_x = test_x[:, 0].cpu().argsort()\n",
    "    ax.plot(\n",
    "        test_x[order_test_x, 0].cpu().numpy(),\n",
    "        pred_means[order_test_x].cpu().numpy(),\n",
    "        color='green',\n",
    "        label='pfn'\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        test_x[order_test_x, 0].cpu().numpy(),\n",
    "        pred_confs[order_test_x][:, 0].cpu().numpy(),\n",
    "        pred_confs[order_test_x][:, 1].cpu().numpy(),\n",
    "        alpha=.1,\n",
    "        color='green'\n",
    "    )\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6073d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import models.encoders as encoders\n",
    "from training_util import get_uniform_single_eval_pos_sampler, get_weighted_single_eval_pos_sampler, get_cosine_schedule_with_warmup\n",
    "import train\n",
    "from criterion.bar_distribution import BarDistribution, get_bucket_limits\n",
    "from models import positional_encodings\n",
    "from prior_generation import gp_prior, gp_lengthscale_prior\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "epochs = 1\n",
    "batch_size =  256\n",
    "warmup_epochs = 25\n",
    "steps_per_epoch = 10\n",
    "lr = 0.0001\n",
    "sequence_length = 10\n",
    "emsize = 512\n",
    "fuse_x_y = False\n",
    "nlayers = 6\n",
    "nhead = 4\n",
    "nhid = 1024\n",
    "dropout = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_buckets = 100\n",
    "min_y = -10\n",
    "max_y = 10\n",
    "num_features = 1\n",
    "num_outputs = 100\n",
    "my_prior_dist = dist.Uniform(low=0.4, high=0.6)\n",
    "sampler = DistributionSampler(my_prior_dist)\n",
    "prior_hyperparameters = {'num_features': num_features, 'num_outputs': num_outputs, 'device': device, 'kernel': \"rbf\", \"length_scale_sampling\": sampler}\n",
    "input_normalization = True\n",
    "aggregate_k_gradients=1\n",
    "encoder_type = 'linear'  # 'linear' or 'mlp'\n",
    "y_encoder_type = 'linear'\n",
    "pos_encoder_type = 'none'  # 'sinus', 'learned', 'none'\n",
    "scheduler = get_cosine_schedule_with_warmup\n",
    "prior_prediction = True\n",
    "num_test_parameters = 1\n",
    "\n",
    "def get_encoder_generator(encoder):\n",
    "        if encoder == 'linear':\n",
    "            encoder_generator = encoders.LinearEncoder\n",
    "        elif encoder == 'mlp':\n",
    "            encoder_generator = encoders.MLPEncoder\n",
    "        else:\n",
    "            raise NotImplementedError(f'A {encoder} encoder is not valid.')\n",
    "        return encoder_generator\n",
    "\n",
    "encoder_generator = get_encoder_generator(encoder_type)\n",
    "y_encoder_generator = get_encoder_generator(y_encoder_type)\n",
    "\n",
    "if pos_encoder_type== 'sinus':\n",
    "    pos_encoder_generator = positional_encodings.PositionalEncoding\n",
    "elif pos_encoder_type == 'learned':\n",
    "    pos_encoder_generator = positional_encodings.LearnedPositionalEncoding\n",
    "else:\n",
    "    pos_encoder_generator = positional_encodings.NoPositionalEncoding\n",
    "    \n",
    "permutation_invariant_max_eval_pos = sequence_length - 1\n",
    "permutation_invariant_sampling = 'uniform'\n",
    "\n",
    "if permutation_invariant_max_eval_pos is not None:\n",
    "    if permutation_invariant_sampling == 'weighted':\n",
    "        get_sampler = get_weighted_single_eval_pos_sampler\n",
    "    elif permutation_invariant_sampling == 'uniform':\n",
    "        get_sampler = get_uniform_single_eval_pos_sampler\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "context_delimiter_generator = get_sampler(permutation_invariant_max_eval_pos)\n",
    "\n",
    "transformer_configuration = (emsize, nhead, nhid, nlayers, dropout, num_features, num_outputs, input_normalization, y_encoder_generator, sequence_length, fuse_x_y, prior_prediction, num_test_parameters) \n",
    "training_configuration = (epochs, steps_per_epoch, batch_size, sequence_length, lr, warmup_epochs, aggregate_k_gradients, scheduler, prior_prediction)\n",
    "generators = (encoder_generator, y_encoder_generator, pos_encoder_generator)\n",
    "# prior = gp_prior.GaussianProcessPriorGenerator()\n",
    "prior = gp_lengthscale_prior.GaussianProcessHyperPriorGenerator()\n",
    "criterion = BarDistribution(borders=get_bucket_limits(num_buckets, full_range=(min_y, max_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52042e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cpu...\n",
      "Using cpu:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss  3.12 | pos loss   nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 3.12, lr 0.0val score 3.027247905731201: 100%|██████████| 1/1 [00:21<00:00, 21.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# 6. Run Training\n",
    "print(f\"Starting training on {device}...\")\n",
    "losses, positional_losses, val_losses,  model = train.train(\n",
    "    prior_dataloader=prior,\n",
    "    criterion=criterion, # Passing the wrapper\n",
    "    transformer_configuration=transformer_configuration,\n",
    "    generators = generators,\n",
    "    training_configuration=training_configuration,\n",
    "    prior_hyperparameters=prior_hyperparameters,\n",
    "    load_path=None,\n",
    "    context_delimiter_generator = context_delimiter_generator,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    save_path=None,\n",
    ")\n",
    "# -7tPNnta8dSg6H33ZZcSz286MQp1OjhjeAk.01.0z1wd0yob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0424c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdakov/.conda/envs/thesis/lib/python3.14/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-03 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_points_in_dataset = 15\n",
    "hyperparameters = { 'kernel': \"rbf\", 'length_scale': 0.5, \"length_scale_sampling\": DistributionSampler(dist.Uniform(low=0.5, high=0.51))}\n",
    "train_X, train_Y, y_target, lengthscale = prior.get_datasets_from_prior(1, num_points_in_dataset, 1, **hyperparameters)\n",
    "train_X = train_X.to(device)\n",
    "train_Y = train_Y.to(device)\n",
    "y_target = y_target.to(device)\n",
    "num_training_points = num_points_in_dataset - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46da943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1, 1]) torch.Size([15, 1])\n",
      "torch.Size([7, 1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "model = model.to(device)\n",
    "# train_x = train_X[:num_training_points]\n",
    "# train_y = train_Y[:num_training_points]\n",
    "\n",
    "train_x = train_X\n",
    "train_y = train_Y\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "with torch.no_grad():\n",
    "    logits = model((train_x, train_y), context_pos=num_training_points - 1)\n",
    "    print(logits.shape)\n",
    "    outputs = torch.exp(torch.log_softmax(logits, -1))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "borders = model.criterion.borders.detach().cpu().numpy() \n",
    "#outputs[1] because this is the lengthscale \n",
    "plt.bar(borders[1:], torch.squeeze(outputs[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
